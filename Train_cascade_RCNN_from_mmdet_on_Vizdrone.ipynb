{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### This nootebook present training model from **MMDET** library on VizDrone2019DET Dataset\n"
      ],
      "metadata": {
        "id": "l-M1I1fz-XZb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUqzWyt-WNQj"
      },
      "outputs": [],
      "source": [
        "%pip install -U openmim\n",
        "!mim install mmcv-full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPY75-2sHjYh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QdzGtp4XtFe"
      },
      "outputs": [],
      "source": [
        "%pip install mmdet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQY7kxVJcPOJ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "!pip install -v -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCC1Ya3HLtvV"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "from mmdet.apis import init_detector, inference_detector\n",
        "import mmcv\n",
        "from mmcv.runner import load_checkpoint\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import sys\n",
        "import os\n",
        "from tqdm import trange\n",
        "import json\n",
        "from torchvision.ops import box_iou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK7ocOt_1BC6"
      },
      "source": [
        "#Register new dataset and define *load_annotation()* function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### VizDrone2019Det classes:\n",
        "\n",
        "* 0:   ignored regions\n",
        "* 1:   pedestrian\n",
        "* 2:   people\n",
        "* 3:   bicycle\n",
        "* 4:   car\n",
        "* 5:   van\n",
        "* 6:   truck\n",
        "* 7:   tricycle\n",
        "* 8:   awning-tricycle\n",
        "* 9:   bus\n",
        "* 10:  motor\n",
        "* 11:  others\n"
      ],
      "metadata": {
        "id": "rTZ0nDkR8rU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hHm9Fh5aZJ64"
      },
      "outputs": [],
      "source": [
        "def get_bbox(path):\n",
        "    with open(path, 'r') as file:\n",
        "        annotation = file.read().strip().split('\\n')\n",
        "        annotation_list=list(map(lambda x: list(map(int, x.split(',')[:6])), annotation))\n",
        "        annotation_list = list(map(lambda a: [a[0], a[1], a[0]+a[2], a[1]+a[3]], list(filter(lambda a: a[5]==2, annotation_list))))\n",
        "        return annotation_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ilHRZu9EP7F6"
      },
      "outputs": [],
      "source": [
        "path_val='/content/drive/MyDrive/VisDrone2019-DET-val/'\n",
        "path_train='/content/drive/MyDrive/VisDrone2019-DET-train/'\n",
        "path_test='/content/drive/MyDrive/VIzDrone2019DET-test/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA1pFg-FeO3l"
      },
      "source": [
        "MMDetection middle format of data\n",
        "\n",
        "```python\n",
        "[\n",
        "    {\n",
        "        'filename': 'a.jpg',\n",
        "        'width': 1280,\n",
        "        'height': 720,\n",
        "        'ann': {\n",
        "            'bboxes': <np.ndarray> (n, 4),\n",
        "            'labels': <np.ndarray> (n, ),\n",
        "            'bboxes_ignore': <np.ndarray> (k, 4), (optional field)\n",
        "            'labels_ignore': <np.ndarray> (k, 4) (optional field)\n",
        "        }\n",
        "    },\n",
        "    ...\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mmdet.datasets.builder import DATASETS\n",
        "from mmdet.datasets.custom import CustomDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "@DATASETS.register_module()\n",
        "class VizdroneDataset(CustomDataset):\n",
        "      CLASSES = ('Person', )\n",
        "\n",
        "      def load_annotations(self, ann_file):\n",
        "          cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
        "          image_list = os.listdir(f'{self.img_prefix}')\n",
        "          data_infos = []\n",
        "          for image_name in tqdm(image_list):\n",
        "              img_path = f'{self.data_root}images/{image_name}'\n",
        "              image = mmcv.imread(img_path)\n",
        "              height, width = image.shape[:2]\n",
        "    \n",
        "              data_info = dict(filename=image_name, width=width, height=height)\n",
        "              # load annotations\n",
        "              label_prefix = f'{self.data_root}/annotations/'\n",
        "              file_name = image_name.split('.')[0] + '.txt'\n",
        "              \n",
        "              bounding_boxes = np.array(get_bbox(f'{label_prefix}{file_name}'), \n",
        "                                dtype=np.float32).reshape(-1, 4)\n",
        "              data_anno = dict(\n",
        "                  bboxes=bounding_boxes,\n",
        "                  labels=np.array([cat2label['Person'] \n",
        "                                   for _ in range(bounding_boxes.shape[0])], dtype=np.long),\n",
        "              )\n",
        "              data_info.update(ann=data_anno)\n",
        "              data_infos.append(data_info)\n",
        "          return data_infos"
      ],
      "metadata": {
        "id": "Xnjx3ZYslHUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j8ZcSi-o_nw"
      },
      "source": [
        "# Load and modify config file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile('./configs/dcn/cascade_rcnn_r101_fpn_dconv_c3-c5_1x_coco.py')"
      ],
      "metadata": {
        "id": "NbtIZqkYxto8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mmdet.apis import set_random_seed\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'VizdroneDataset'\n",
        "cfg.data_root = '/content/drive/MyDrive/'\n",
        "#Test data configurations\n",
        "cfg.data.test.type = 'VizdroneDataset'\n",
        "cfg.data.test.data_root = '/content/drive/MyDrive/VIzDrone2019DET-test/'\n",
        "cfg.data.test.img_prefix = 'images/'\n",
        "#Train data configurations\n",
        "cfg.data.train.type = 'VizdroneDataset'\n",
        "cfg.data.train.data_root = '/content/drive/MyDrive/VisDrone2019-DET-train/'\n",
        "#tranformations\n",
        "cfg.data.train.pipeline = [\n",
        "     {'type': 'LoadImageFromFile'},\n",
        "     {'type': 'LoadAnnotations', 'with_bbox': True},\n",
        "     {'type': 'Resize', 'img_scale': (1333, 800), 'keep_ratio': True},\n",
        "     {'type': 'RandomFlip', 'flip_ratio': 0.5, 'direction': ['horizontal']},\n",
        "     {'type': \"Albu\", 'transforms': [\n",
        "         dict(type='RandomBrightnessContrast', brightness_limit=0.2,\n",
        "              contrast_limit=0.2, p=0.5),\n",
        "         dict(type='GaussNoise'),\n",
        "         dict(type='ShiftScaleRotate', shift_limit=0.0625,\n",
        "              scale_limit=0.1, rotate_limit=45, p=0.4),\n",
        "     ],\n",
        "      'bbox_params': \n",
        "         dict(\n",
        "             type='BboxParams',\n",
        "             format='pascal_voc',\n",
        "             \n",
        "             label_fields=['gt_labels'],\n",
        "             min_visibility=0.0,\n",
        "             filter_lost_elements=True),\n",
        "         'keymap': {\n",
        "         'img': 'image',\n",
        "         'gt_bboxes': 'bboxes'\n",
        "         }\n",
        "    },\n",
        "    {'type': 'CutOut', 'n_holes': (0, 3), 'cutout_ratio': (0.05, 0.2)},\n",
        "    {'type': 'Normalize',\n",
        "     'mean': [123.675, 116.28, 103.53],\n",
        "     'std': [58.395, 57.12, 57.375],\n",
        "     'to_rgb': True},\n",
        "    {'type': 'Pad', 'size_divisor': 32},\n",
        "    {'type': 'DefaultFormatBundle'},\n",
        "    {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}\n",
        "]\n",
        "cfg.data.train.img_prefix = 'images/'\n",
        "\n",
        "cfg.data.val.type = 'VizdroneDataset'\n",
        "cfg.data.val.data_root = '/content/drive/MyDrive/VisDrone2019-DET-val/'\n",
        "cfg.data.val.img_prefix = 'images/'\n",
        "# modify num classes of the model in box head\n",
        "for layer in cfg.model.roi_head.bbox_head:\n",
        "    layer.num_classes = 1\n",
        "#Path to load pretrained model\n",
        "cfg.load_from = '/content/drive/MyDrive/training_on_vizdrone/model2.pth'\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = '/content/drive/MyDrive/training_on_vizdrone/'\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "cfg.optimizer.lr = 0.02 / 12\n",
        "cfg.lr_config.warmup_ratio = 1e-4\n",
        "cfg.log_config.interval = 10\n",
        "\n",
        "cfg.custom_imports = dict(\n",
        "     imports=['mmdet.datasets.VizdroneDataset'],\n",
        "     allow_failed_imports=False)\n",
        "# Change the evaluation metric since we use customized dataset.\n",
        "cfg.evaluation.metric = 'mAP'\n",
        "# We can set the evaluation interval to reduce the evaluation times\n",
        "cfg.evaluation.interval = 1\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 1\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "cfg.device = 'cuda'\n",
        "cfg.runner.max_epochs = 6\n",
        "# We can initialize the logger for training and have a look\n",
        "# at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n"
      ],
      "metadata": {
        "id": "u_E14wop1CNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build detector, dataset and start training"
      ],
      "metadata": {
        "id": "YasXbJlrBbO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "# Build the detector\n",
        "model = build_detector(\n",
        "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
        "model.CLASSES = datasets[0].CLASSES"
      ],
      "metadata": {
        "id": "w6pv5Zcn4qNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_detector(model, datasets, cfg, distributed=False, validate=True)"
      ],
      "metadata": {
        "id": "at_QG9Z4D1F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save configs and test detector on test data"
      ],
      "metadata": {
        "id": "Pjh23EmxBz-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ATTENTION!!! \\\n",
        "To test model its necessary create file with *class VizdroneDataset(CustomDataset)* defenition and put it into mmdetection/mmdet/datasets/VizdroneDataset.py"
      ],
      "metadata": {
        "id": "ZE85R-MMB7oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.dump('/content/configs.py')"
      ],
      "metadata": {
        "id": "ZVVNo68KBzfW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = Config.fromfile('/content/configs.py')"
      ],
      "metadata": {
        "id": "n_pxZkg4gT_P"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/test.py \\\n",
        "    /content/configs.py \\\n",
        "    /content/drive/MyDrive/training_on_vizdrone/model2.pth \\\n",
        "    --eval mAP --work-dir /content/metrics"
      ],
      "metadata": {
        "id": "Jq2vnS8UD1S_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}